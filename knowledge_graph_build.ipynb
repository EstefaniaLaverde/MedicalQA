{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e56d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: networkx in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (3.2.1)\n",
      "Requirement already satisfied: pandas in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: rdflib in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (7.4.0)\n",
      "Requirement already satisfied: requests in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: retrying in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from rdflib) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: six>=1.5 in /Users/esanto/Documents/personal/Uniandes/NLP/Proyecto/.venv/lib/python3.11/site-packages (from python-dateutil) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install SPARQLWrapper networkx pandas tqdm rdflib requests retrying python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0de1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√≥dulo de enriquecimiento m√©dico inicializado\n",
      "DBpedia EN: https://dbpedia.org/sparql\n",
      "DBpedia ES: https://es.dbpedia.org/sparql\n",
      "Wikidata: https://query.wikidata.org/sparql\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sistema de Enriquecimiento de Datos M√©dicos desde DBpedia y Wikidata\n",
    "=====================================================================\n",
    "Este m√≥dulo consulta DBpedia y Wikidata para obtener informaci√≥n m√©dica estructurada\n",
    "que enriquecer√° el corpus CoWeSe para el sistema RAG.\n",
    "\"\"\"\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from retrying import retry\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Endpoints SPARQL\n",
    "DBPEDIA_SPARQL = \"https://dbpedia.org/sparql\"\n",
    "DBPEDIA_ES_SPARQL = \"https://es.dbpedia.org/sparql\"\n",
    "WIKIDATA_SPARQL = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# User agent recomendado\n",
    "USER_AGENT = \"MedicalKG-RAG/1.0 (educational project; e.santofimio@uniandes.edu.co)\"\n",
    "\n",
    "print(\"M√≥dulo de enriquecimiento m√©dico inicializado\")\n",
    "print(f\"DBpedia EN: {DBPEDIA_SPARQL}\")\n",
    "print(f\"DBpedia ES: {DBPEDIA_ES_SPARQL}\")\n",
    "print(f\"Wikidata: {WIKIDATA_SPARQL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf05e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000, stop_max_attempt_number=5)\n",
    "def run_sparql_query(query: str, endpoint: str = DBPEDIA_SPARQL, timeout: int = 60) -> Dict:\n",
    "    \"\"\"\n",
    "    Ejecutar consulta SPARQL con reintentos autom√°ticos\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta SPARQL\n",
    "        endpoint: Endpoint SPARQL a usar\n",
    "        timeout: Timeout en segundos\n",
    "        \n",
    "    Returns:\n",
    "        Resultados en formato JSON\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(endpoint, agent=USER_AGENT)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setTimeout(timeout)\n",
    "    \n",
    "    try:\n",
    "        result = sparql.query().convert()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error en consulta SPARQL: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8f3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consultando DBpedia por 300 enfermedades...\n",
      "Obtenidas 300 enfermedades de DBpedia\n"
     ]
    }
   ],
   "source": [
    "def get_diseases_from_dbpedia(limit: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtener enfermedades desde DBpedia con descripciones y propiedades\n",
    "    \n",
    "    Args:\n",
    "        limit: N√∫mero m√°ximo de enfermedades a recuperar\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con informaci√≥n de enfermedades\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbp: <http://dbpedia.org/property/>\n",
    "    \n",
    "    SELECT DISTINCT \n",
    "        ?disease \n",
    "        ?label \n",
    "        ?abstract\n",
    "        (GROUP_CONCAT(DISTINCT ?symptom; separator=\"|\") AS ?symptoms)\n",
    "        (GROUP_CONCAT(DISTINCT ?treatment; separator=\"|\") AS ?treatments)\n",
    "        (GROUP_CONCAT(DISTINCT ?cause; separator=\"|\") AS ?causes)\n",
    "    WHERE {{\n",
    "        # Enfermedades\n",
    "        ?disease a dbo:Disease .\n",
    "        ?disease rdfs:label ?label .\n",
    "        FILTER(LANG(?label) = \"es\" || LANG(?label) = \"en\")\n",
    "        \n",
    "        # Resumen/descripci√≥n\n",
    "        OPTIONAL {{ \n",
    "            ?disease dbo:abstract ?abstract .\n",
    "            FILTER(LANG(?abstract) = \"es\")\n",
    "        }}\n",
    "        \n",
    "        # S√≠ntomas\n",
    "        OPTIONAL {{ ?disease dbo:symptom ?symptom }}\n",
    "        \n",
    "        # Tratamientos\n",
    "        OPTIONAL {{ ?disease dbo:treatment ?treatment }}\n",
    "        \n",
    "        # Causas\n",
    "        OPTIONAL {{ ?disease dbp:causes ?cause }}\n",
    "    }}\n",
    "    GROUP BY ?disease ?label ?abstract\n",
    "    LIMIT {limit}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Consultando DBpedia por {limit} enfermedades...\")\n",
    "    results = run_sparql_query(query, endpoint=DBPEDIA_SPARQL)\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    bindings = results.get('results', {}).get('bindings', [])\n",
    "    \n",
    "    data = []\n",
    "    for binding in bindings:\n",
    "        data.append({\n",
    "            'uri': binding.get('disease', {}).get('value', ''),\n",
    "            'nombre': binding.get('label', {}).get('value', ''),\n",
    "            'descripcion': binding.get('abstract', {}).get('value', ''),\n",
    "            'sintomas': binding.get('symptoms', {}).get('value', '').split('|') if binding.get('symptoms', {}).get('value') else [],\n",
    "            'tratamientos': binding.get('treatments', {}).get('value', '').split('|') if binding.get('treatments', {}).get('value') else [],\n",
    "            'causas': binding.get('causes', {}).get('value', '').split('|') if binding.get('causes', {}).get('value') else []\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Obtenidas {len(df)} enfermedades de DBpedia\")\n",
    "    return df\n",
    "\n",
    "# Ejecutar consulta\n",
    "diseases_df = get_diseases_from_dbpedia(limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f636abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra de enfermedades obtenidas:\n",
      "Total: 300 enfermedades\n",
      "Encefalitis japonesa\n",
      "S√≠ntomas: Seizure\n",
      "Tratamientos: Symptomatic_treatment\n",
      "\n",
      "Insomnio familiar letal\n",
      "S√≠ntomas: Ataxia, Diplopia\n",
      "Tratamientos: Symptomatic_treatment\n",
      "\n",
      "Fractura de pelvis\n",
      "Tratamientos: Embolization, Fluid_replacement, Pelvic_binder\n",
      "\n",
      "Sirenomelia\n",
      "Tratamientos: Surgery\n",
      "\n",
      "Jones fracture\n",
      "Tratamientos: Orthopedic_cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar primeros resultados\n",
    "print(f\"Muestra de enfermedades obtenidas:\")\n",
    "print(f\"Total: {len(diseases_df)} enfermedades\")\n",
    "\n",
    "if not diseases_df.empty:\n",
    "    for idx, row in diseases_df.head(5).iterrows():\n",
    "        print(f\"{row['nombre']}\")\n",
    "        if row['descripcion']:\n",
    "            desc = row['descripcion'][:200] + \"...\" if len(row['descripcion']) > 200 else row['descripcion']\n",
    "            print(f\" {desc}\")\n",
    "        if row['sintomas']:\n",
    "            print(f\"S√≠ntomas: {', '.join([s.split('/')[-1] for s in row['sintomas'][:3]])}\")\n",
    "        if row['tratamientos']:\n",
    "            print(f\"Tratamientos: {', '.join([t.split('/')[-1] for t in row['tratamientos'][:3]])}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No se obtuvieron resultados de DBpedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0adc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Consultando DBpedia ES por 200 enfermedades...\n",
      "‚úì Obtenidas 200 enfermedades de DBpedia ES\n"
     ]
    }
   ],
   "source": [
    "def get_diseases_spanish_dbpedia(limit: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtener enfermedades desde DBpedia en espa√±ol con informaci√≥n rica\n",
    "    \n",
    "    Args:\n",
    "        limit: N√∫mero de enfermedades\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con informaci√≥n en espa√±ol\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    \n",
    "    SELECT DISTINCT ?disease ?label ?abstract\n",
    "    WHERE {{\n",
    "        ?disease a dbo:Disease .\n",
    "        ?disease rdfs:label ?label .\n",
    "        FILTER(LANG(?label) = \"es\")\n",
    "        \n",
    "        ?disease dbo:abstract ?abstract .\n",
    "        FILTER(LANG(?abstract) = \"es\")\n",
    "        \n",
    "        # Solo enfermedades con resumen en espa√±ol\n",
    "        FILTER(STRLEN(?abstract) > 200)\n",
    "    }}\n",
    "    LIMIT {limit}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîç Consultando DBpedia ES por {limit} enfermedades...\")\n",
    "    try:\n",
    "        results = run_sparql_query(query, endpoint=DBPEDIA_ES_SPARQL)\n",
    "        \n",
    "        bindings = results.get('results', {}).get('bindings', [])\n",
    "        \n",
    "        data = []\n",
    "        for binding in bindings:\n",
    "            data.append({\n",
    "                'uri': binding.get('disease', {}).get('value', ''),\n",
    "                'nombre': binding.get('label', {}).get('value', ''),\n",
    "                'descripcion': binding.get('abstract', {}).get('value', '')\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        print(f\"‚úì Obtenidas {len(df)} enfermedades de DBpedia ES\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error consultando DBpedia ES: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Ejecutar consulta\n",
    "diseases_es_df = get_diseases_spanish_dbpedia(limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "811149b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enfermedades con descripciones en espa√±ol:\n",
      "Total: 200 enfermedades\n",
      "Arco a√≥rtico doble\n",
      "Descripci√≥n:\n",
      "El arco a√≥rtico doble es una malformaci√≥n cardiovascular cong√©nita relativamente rara. El AAD es una anomal√≠a del arco a√≥rtico en el que dos arcos a√≥rticos forman un anillo vascular completo que puede comprimir la tr√°quea y / o el es√≥fago . ‚Äã ‚Äã Por lo general, hay un arco derecho m√°s grande (dominante) detr√°s y un arco a√≥rtico izquierdo m√°s peque√±o ( hipopl√°sico ) delante de la tr√°quea / es√≥fago. Los dos arcos se unen para formar la aorta descendente, que generalmente est√° en el lado izquierdo (pero puede ser del lado derecho o en la l√≠nea media). En algunos casos, el extremo del arco a√≥rtico izquierdo m√°s peque√±o se cierra (arco atr√©sico izquierdo) y el tejido vascular se convierte en un cord√≥n fibroso. Aunque en estos casos no est√° presente un anillo completo de dos arcos a√≥rticos patentes, el t√©rmino \"anillo vascular\" es el t√©rmino gen√©rico aceptado incluso en estas anomal√≠as. Los s√≠ntomas est√°n relacionados con la compresi√≥n de la tr√°quea, el es√≥fago o ambos por el anillo vascular completo. El diagn√≥stico a menudo puede sospecharse o realizarse mediante una radiograf√≠a de t√≥rax, esofagrama de bario o ecocardiograf√≠a. La tomograf√≠a computarizada (TC) o la resonancia magn√©tica (RM) muestran la relaci√≥n de los arcos a√≥rticos con la tr√°quea y el es√≥fago y tambi√©n el grado de estrechamiento traqueal. La broncoscopia puede ser √∫til para evaluar internamente el grado de traqueomalacia . El tratamiento es quir√∫rgico y est√° indicado en todos los pacientes sintom√°ticos. En la era actual, el riesgo de mortalidad o morbilidad significativa despu√©s de la divisi√≥n quir√∫rgica del arco menor es bajo. Sin embargo, el grado preoperatorio de traqueomalacia tiene un impacto importante en la recuperaci√≥n postoperatoria. En ciertos pacientes pueden pasar varios meses (hasta 1 a 2 a√±os) para que desaparezcan los s√≠ntomas respiratorios obstructivos (sibilancias).\n",
      "Aspergiloma\n",
      "Descripci√≥n:\n",
      "En medicina, se llama aspergiloma a una masa redondeada formada por hifas de hongos del g√©nero Aspergillus que se localiza dentro de un quiste o cavidad. Generalmente afecta al pulm√≥n, aunque en ocasiones se presenta en otros √≥rganos como el ri√±√≥n y el cerebro. La especie causante m√°s habitual es Aspergillus fumigatus. El aspergiloma es una de las formas de presentaci√≥n de la aspergilosis, debe distinguirse de la aspergilosis invasiva y la aspergilosis broncopulmonar al√©rgica.\n",
      "Aspergilosis broncopulmonar al√©rgica\n",
      "Descripci√≥n:\n",
      "La aspergilosis broncopulmonar al√©rgidudkddbgdshspitona enfermedad pulmonar provocada por una respuesta exagerada del sistema inmune al hongo Aspergillus. Debe diferenciasrse de otras formas de aspergilosis, entre ellas el aspergiloma y la aspergilosis pulmonar invasiva. Se produce sobre todo en pacientes afectados por asma bronquial o fibrosis qu√≠stica y se debe a un mecanismo de hipersensibilidad al Aspergillus que desencadena una respuesta inflamatoria en las v√≠as respiratoria que puede ocasionar dilataci√≥n an√≥mala de los bronquios (bronquiectasias) y provocar secuelas irreversibles en la funci√≥n pulmonar. Para alcanzar el diagn√≥stico es √∫til la radiolog√≠a de t√≥rax es la que pueden observarse opacidades tubulares ramificadas de elevada densidad que se extienden desde el hilio pulmonar hasta la perifer√≠a y est√°n causadas por impactos mucosos con dep√≥sitos de sales de calcio. En el an√°lisis de sangre puede existir aumento del n√∫mero de eosin√≥filos (eosinofilia), en los test cut√°neos se comprueba hipersensibilidad a Aspergillus, dato no espec√≠fico que aparece en un alto porcentaje de personas asm√°tica que no presentan aspergilosis broncopulmonar. El tratamiento se realiza con corticoides y en ocasiones medicamentos antif√∫ngicos como el itraconazol. ‚Äã ‚Äã ‚Äã\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resultados en espa√±ol\n",
    "print(f\"Enfermedades con descripciones en espa√±ol:\")\n",
    "\n",
    "if not diseases_es_df.empty:\n",
    "    print(f\"Total: {len(diseases_es_df)} enfermedades\")\n",
    "    \n",
    "    for idx, row in diseases_es_df.head(3).iterrows():\n",
    "        print(f\"{row['nombre']}\")\n",
    "        print(f\"Descripci√≥n:\")\n",
    "        desc = row['descripcion']\n",
    "        print(f\"{desc}\")\n",
    "else:\n",
    "    print(\"No se obtuvieron resultados de DBpedia ES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cbd392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consultando Wikidata (offset=0, limit=600)...\n",
      "‚úì Obtenidos 600 registros de Wikidata\n"
     ]
    }
   ],
   "source": [
    "def get_wikidata_diseases(limit: int = 500, offset: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtener enfermedades de Wikidata con relaciones estructuradas\n",
    "    \n",
    "    Args:\n",
    "        limit: L√≠mite de resultados\n",
    "        offset: Desplazamiento para paginaci√≥n\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con enfermedades y relaciones\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        ?disease ?diseaseLabel \n",
    "        ?symptomLabel \n",
    "        ?treatmentLabel\n",
    "        ?causeLabel\n",
    "        ?drugLabel\n",
    "    WHERE {{\n",
    "        # Enfermedades (instancia o subclase de enfermedad)\n",
    "        ?disease wdt:P31/wdt:P279* wd:Q12136 .\n",
    "        \n",
    "        # S√≠ntomas\n",
    "        OPTIONAL {{ \n",
    "            ?disease wdt:P780 ?symptom .\n",
    "        }}\n",
    "        \n",
    "        # Tratamientos\n",
    "        OPTIONAL {{ \n",
    "            ?disease wdt:P2176 ?treatment .\n",
    "        }}\n",
    "        \n",
    "        # Causas\n",
    "        OPTIONAL {{ \n",
    "            ?disease wdt:P828 ?cause .\n",
    "        }}\n",
    "        \n",
    "        # Medicamentos usados\n",
    "        OPTIONAL {{\n",
    "            ?disease wdt:P2176 ?drug .\n",
    "            ?drug wdt:P31/wdt:P279* wd:Q12140 .\n",
    "        }}\n",
    "        \n",
    "        # Etiquetas en espa√±ol\n",
    "        SERVICE wikibase:label {{ \n",
    "            bd:serviceParam wikibase:language \"es,en\" . \n",
    "        }}\n",
    "    }}\n",
    "    LIMIT {limit}\n",
    "    OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Consultando Wikidata (offset={offset}, limit={limit})...\")\n",
    "    results = run_sparql_query(query, endpoint=WIKIDATA_SPARQL, timeout=120)\n",
    "    \n",
    "    bindings = results.get('results', {}).get('bindings', [])\n",
    "    \n",
    "    data = []\n",
    "    for binding in bindings:\n",
    "        data.append({\n",
    "            'uri': binding.get('disease', {}).get('value', ''),\n",
    "            'enfermedad': binding.get('diseaseLabel', {}).get('value', ''),\n",
    "            'sintoma': binding.get('symptomLabel', {}).get('value', ''),\n",
    "            'tratamiento': binding.get('treatmentLabel', {}).get('value', ''),\n",
    "            'causa': binding.get('causeLabel', {}).get('value', ''),\n",
    "            'medicamento': binding.get('drugLabel', {}).get('value', '')\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"‚úì Obtenidos {len(df)} registros de Wikidata\")\n",
    "    return df\n",
    "\n",
    "# Ejecutar consulta con retry\n",
    "try:\n",
    "    wikidata_df = get_wikidata_diseases(limit=600)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Intentando con menos resultados...\")\n",
    "    wikidata_df = get_wikidata_diseases(limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39964a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de Wikidata...\n",
      "Total de enfermedades √∫nicas: 216\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Abetalipoproteinemia\n",
      "\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Acromatopsia\n",
      "S√≠ntomas: nistagmo, fotofobia, ambliop√≠a\n",
      "\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Adams-Oliver syndrome\n",
      "\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Adermatoglifia\n",
      "\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Adrenoleucodistrofia\n",
      "Tratamientos: Aceite de Lorenzo\n",
      " Medicamentos: Aceite de Lorenzo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupar datos por enfermedad\n",
    "print(f\"Procesando datos de Wikidata...\")\n",
    "\n",
    "if not wikidata_df.empty:\n",
    "    # Agrupar por enfermedad\n",
    "    wikidata_grouped = wikidata_df.groupby('enfermedad').agg({\n",
    "        'uri': 'first',\n",
    "        'sintoma': lambda x: list(set([s for s in x if s])),\n",
    "        'tratamiento': lambda x: list(set([t for t in x if t])),\n",
    "        'causa': lambda x: list(set([c for c in x if c])),\n",
    "        'medicamento': lambda x: list(set([m for m in x if m]))\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(f\"Total de enfermedades √∫nicas: {len(wikidata_grouped)}\")\n",
    "    \n",
    "    # Mostrar ejemplos\n",
    "    for idx, row in wikidata_grouped.head(5).iterrows():\n",
    "        print(f\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "        print(f\"{row['enfermedad']}\")\n",
    "        \n",
    "        if row['sintoma']:\n",
    "            sintomas = [s for s in row['sintoma'] if s][:5]\n",
    "            if sintomas:\n",
    "                print(f\"S√≠ntomas: {', '.join(sintomas)}\")\n",
    "        \n",
    "        if row['tratamiento']:\n",
    "            tratamientos = [t for t in row['tratamiento'] if t][:3]\n",
    "            if tratamientos:\n",
    "                print(f\"Tratamientos: {', '.join(tratamientos)}\")\n",
    "        \n",
    "        if row['medicamento']:\n",
    "            medicamentos = [m for m in row['medicamento'] if m][:3]\n",
    "            if medicamentos:\n",
    "                print(f\" Medicamentos: {', '.join(medicamentos)}\")\n",
    "        \n",
    "        if row['causa']:\n",
    "            causas = [c for c in row['causa'] if c][:2]\n",
    "            if causas:\n",
    "                print(f\"Causas: {', '.join(causas)}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No se obtuvieron datos de Wikidata\")\n",
    "    wikidata_grouped = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c47b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de DBpedia EN...\n",
      "DBpedia EN: 299 enfermedades procesadas\n",
      "Procesando datos de DBpedia ES...\n",
      "DBpedia ES: 495 enfermedades totales\n",
      "Procesando datos de Wikidata...\n",
      "Wikidata procesado\n",
      "\n",
      "============================================================\n",
      "RESUMEN DEL GRAFO DE CONOCIMIENTO\n",
      "============================================================\n",
      "Enfermedades: 705\n",
      "Sintomas: 160\n",
      "Tratamientos: 184\n",
      "Medicamentos: 4\n",
      "Causas: 87\n",
      "Relaciones: 499\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def prepare_neo4j_data():\n",
    "  \"\"\"\n",
    "  Preparar datos estructurados para importar en Neo4j\n",
    "  Combina informaci√≥n de DBpedia y Wikidata sin URLs\n",
    "  \"\"\"\n",
    "  \n",
    "  # Diccionarios para almacenar entidades √∫nicas\n",
    "  diseases = {}\n",
    "  symptoms = {}\n",
    "  treatments = {}\n",
    "  causes = {}\n",
    "  medications = {}\n",
    "  relationships = []\n",
    "  \n",
    "  print(\"Procesando datos de DBpedia EN...\")\n",
    "  # Procesar DBpedia EN\n",
    "  for idx, row in diseases_df.iterrows():\n",
    "    disease_name = row['nombre'].strip()\n",
    "    \n",
    "    # Agregar enfermedad\n",
    "    if disease_name and disease_name not in diseases:\n",
    "      diseases[disease_name] = {\n",
    "        'name': disease_name,\n",
    "        'description': row['descripcion'].strip() if row['descripcion'] else '',\n",
    "        'source': 'DBpedia EN'\n",
    "      }\n",
    "    \n",
    "    # Procesar s√≠ntomas\n",
    "    if row['sintomas']:\n",
    "      for symptom_uri in row['sintomas']:\n",
    "        if symptom_uri:\n",
    "          symptom_name = symptom_uri.split('/')[-1].replace('_', ' ')\n",
    "          if symptom_name and symptom_name not in symptoms:\n",
    "            symptoms[symptom_name] = {'name': symptom_name}\n",
    "          \n",
    "          if symptom_name:\n",
    "            relationships.append({\n",
    "              'type': 'HAS_SYMPTOM',\n",
    "              'from': disease_name,\n",
    "              'to': symptom_name,\n",
    "              'from_type': 'Disease',\n",
    "              'to_type': 'Symptom'\n",
    "            })\n",
    "    \n",
    "    # Procesar tratamientos\n",
    "    if row['tratamientos']:\n",
    "      for treatment_uri in row['tratamientos']:\n",
    "        if treatment_uri:\n",
    "          treatment_name = treatment_uri.split('/')[-1].replace('_', ' ')\n",
    "          if treatment_name and treatment_name not in treatments:\n",
    "            treatments[treatment_name] = {'name': treatment_name}\n",
    "          \n",
    "          if treatment_name:\n",
    "            relationships.append({\n",
    "              'type': 'TREATED_WITH',\n",
    "              'from': disease_name,\n",
    "              'to': treatment_name,\n",
    "              'from_type': 'Disease',\n",
    "              'to_type': 'Treatment'\n",
    "            })\n",
    "    \n",
    "    # Procesar causas\n",
    "    if row['causas']:\n",
    "      for cause_item in row['causas']:\n",
    "        if cause_item:\n",
    "          # Limpiar causa (puede ser texto o URI)\n",
    "          if 'http' in cause_item:\n",
    "            cause_name = cause_item.split('/')[-1].replace('_', ' ')\n",
    "          else:\n",
    "            cause_name = cause_item.strip()\n",
    "          \n",
    "          if cause_name and cause_name not in causes:\n",
    "            causes[cause_name] = {'name': cause_name}\n",
    "          \n",
    "          if cause_name:\n",
    "            relationships.append({\n",
    "              'type': 'CAUSED_BY',\n",
    "              'from': disease_name,\n",
    "              'to': cause_name,\n",
    "              'from_type': 'Disease',\n",
    "              'to_type': 'Cause'\n",
    "            })\n",
    "  \n",
    "  print(f\"DBpedia EN: {len(diseases)} enfermedades procesadas\")\n",
    "  \n",
    "  print(\"Procesando datos de DBpedia ES...\")\n",
    "  # Procesar DBpedia ES (descripciones en espa√±ol)\n",
    "  for idx, row in diseases_es_df.iterrows():\n",
    "    disease_name = row['nombre'].strip()\n",
    "    description = row['descripcion'].strip()\n",
    "    \n",
    "    if disease_name:\n",
    "      if disease_name in diseases:\n",
    "        # Actualizar con descripci√≥n en espa√±ol si es m√°s completa\n",
    "        if len(description) > len(diseases[disease_name].get('description', '')):\n",
    "          diseases[disease_name]['description'] = description\n",
    "          diseases[disease_name]['source'] = 'DBpedia ES'\n",
    "      else:\n",
    "        diseases[disease_name] = {\n",
    "          'name': disease_name,\n",
    "          'description': description,\n",
    "          'source': 'DBpedia ES'\n",
    "        }\n",
    "  \n",
    "  print(f\"DBpedia ES: {len(diseases)} enfermedades totales\")\n",
    "  \n",
    "  print(\"Procesando datos de Wikidata...\")\n",
    "  # Procesar Wikidata\n",
    "  for idx, row in wikidata_grouped.iterrows():\n",
    "    disease_name = row['enfermedad'].strip()\n",
    "    \n",
    "    # Agregar enfermedad\n",
    "    if disease_name and disease_name not in diseases:\n",
    "      diseases[disease_name] = {\n",
    "        'name': disease_name,\n",
    "        'description': '',\n",
    "        'source': 'Wikidata'\n",
    "      }\n",
    "    \n",
    "    # Procesar s√≠ntomas\n",
    "    if row['sintoma']:\n",
    "      for symptom_name in row['sintoma']:\n",
    "        if symptom_name:\n",
    "          symptom_name = symptom_name.strip()\n",
    "          if symptom_name not in symptoms:\n",
    "            symptoms[symptom_name] = {'name': symptom_name}\n",
    "          \n",
    "          relationships.append({\n",
    "            'type': 'HAS_SYMPTOM',\n",
    "            'from': disease_name,\n",
    "            'to': symptom_name,\n",
    "            'from_type': 'Disease',\n",
    "            'to_type': 'Symptom'\n",
    "          })\n",
    "    \n",
    "    # Procesar tratamientos\n",
    "    if row['tratamiento']:\n",
    "      for treatment_name in row['tratamiento']:\n",
    "        if treatment_name:\n",
    "          treatment_name = treatment_name.strip()\n",
    "          if treatment_name not in treatments:\n",
    "            treatments[treatment_name] = {'name': treatment_name}\n",
    "          \n",
    "          relationships.append({\n",
    "            'type': 'TREATED_WITH',\n",
    "            'from': disease_name,\n",
    "            'to': treatment_name,\n",
    "            'from_type': 'Disease',\n",
    "            'to_type': 'Treatment'\n",
    "          })\n",
    "    \n",
    "    # Procesar medicamentos\n",
    "    if row['medicamento']:\n",
    "      for medication_name in row['medicamento']:\n",
    "        if medication_name:\n",
    "          medication_name = medication_name.strip()\n",
    "          if medication_name not in medications:\n",
    "            medications[medication_name] = {'name': medication_name}\n",
    "          \n",
    "          relationships.append({\n",
    "            'type': 'USES_MEDICATION',\n",
    "            'from': disease_name,\n",
    "            'to': medication_name,\n",
    "            'from_type': 'Disease',\n",
    "            'to_type': 'Medication'\n",
    "          })\n",
    "    \n",
    "    # Procesar causas\n",
    "    if row['causa']:\n",
    "      for cause_name in row['causa']:\n",
    "        if cause_name:\n",
    "          cause_name = cause_name.strip()\n",
    "          if cause_name not in causes:\n",
    "            causes[cause_name] = {'name': cause_name}\n",
    "          \n",
    "          relationships.append({\n",
    "            'type': 'CAUSED_BY',\n",
    "            'from': disease_name,\n",
    "            'to': cause_name,\n",
    "            'from_type': 'Disease',\n",
    "            'to_type': 'Cause'\n",
    "          })\n",
    "  \n",
    "  print(f\"Wikidata procesado\")\n",
    "  \n",
    "  # Convertir diccionarios a listas\n",
    "  neo4j_graph = {\n",
    "    'nodes': {\n",
    "      'diseases': [{'id': name, **data} for name, data in diseases.items()],\n",
    "      'symptoms': [{'id': name, **data} for name, data in symptoms.items()],\n",
    "      'treatments': [{'id': name, **data} for name, data in treatments.items()],\n",
    "      'causes': [{'id': name, **data} for name, data in causes.items()],\n",
    "      'medications': [{'id': name, **data} for name, data in medications.items()]\n",
    "    },\n",
    "    'relationships': relationships\n",
    "  }\n",
    "  \n",
    "  # Estad√≠sticas\n",
    "  print(\"\\n\" + \"=\"*60)\n",
    "  print(\"RESUMEN DEL GRAFO DE CONOCIMIENTO\")\n",
    "  print(\"=\"*60)\n",
    "  print(f\"Enfermedades: {len(diseases)}\")\n",
    "  print(f\"Sintomas: {len(symptoms)}\")\n",
    "  print(f\"Tratamientos: {len(treatments)}\")\n",
    "  print(f\"Medicamentos: {len(medications)}\")\n",
    "  print(f\"Causas: {len(causes)}\")\n",
    "  print(f\"Relaciones: {len(relationships)}\")\n",
    "  print(\"=\"*60)\n",
    "  \n",
    "  return neo4j_graph\n",
    "\n",
    "# Preparar datos\n",
    "neo4j_graph = prepare_neo4j_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "748f47b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Guardado en JSON: medical_knowledge_graph_20251120_211246.json\n",
      "‚úì Guardado en Pickle: medical_knowledge_graph_20251120_211246.pkl\n",
      "‚úì Guardado resumen en: medical_kg_summary_20251120_211246.txt\n",
      "‚úì Guardados nodos en CSV: medical_kg_nodes_20251120_211246.csv\n",
      "‚úì Guardadas relaciones en CSV: medical_kg_relationships_20251120_211246.csv\n",
      "\n",
      "======================================================================\n",
      "ARCHIVOS GUARDADOS EXITOSAMENTE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "def save_knowledge_graph(neo4j_graph: Dict, base_filename: str = \"medical_knowledge_graph\") -> Dict[str, str]:\n",
    "  \"\"\"\n",
    "  Guardar el grafo de conocimiento en m√∫ltiples formatos\n",
    "  \n",
    "  Args:\n",
    "    neo4j_graph: Diccionario con nodos y relaciones del grafo\n",
    "    base_filename: Nombre base para los archivos\n",
    "    \n",
    "  Returns:\n",
    "    Diccionario con las rutas de los archivos guardados\n",
    "  \"\"\"\n",
    "  \n",
    "  # Generar timestamp para versionar archivos\n",
    "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  \n",
    "  saved_files = {}\n",
    "  \n",
    "  # 1. Guardar en JSON (legible, para importar en Neo4j)\n",
    "  json_filename = f\"{base_filename}_{timestamp}.json\"\n",
    "  with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(neo4j_graph, f, ensure_ascii=False, indent=2)\n",
    "  saved_files['json'] = json_filename\n",
    "  print(f\"‚úì Guardado en JSON: {json_filename}\")\n",
    "  \n",
    "  # 2. Guardar en Pickle (r√°pido, para Python)\n",
    "  pickle_filename = f\"{base_filename}_{timestamp}.pkl\"\n",
    "  with open(pickle_filename, 'wb') as f:\n",
    "    pickle.dump(neo4j_graph, f)\n",
    "  saved_files['pickle'] = pickle_filename\n",
    "  print(f\"‚úì Guardado en Pickle: {pickle_filename}\")\n",
    "  \n",
    "  # 3. Guardar resumen en texto\n",
    "  summary_filename = f\"medical_kg_summary_{timestamp}.txt\"\n",
    "  with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\" * 70 + \"\\n\")\n",
    "    f.write(\"RESUMEN DEL GRAFO DE CONOCIMIENTO M√âDICO\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Fecha de generaci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    # Estad√≠sticas de nodos\n",
    "    f.write(\"NODOS:\\n\")\n",
    "    f.write(\"-\" * 70 + \"\\n\")\n",
    "    for node_type, nodes in neo4j_graph['nodes'].items():\n",
    "      f.write(f\"  {node_type.capitalize()}: {len(nodes)}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nRELACIONES: {len(neo4j_graph['relationships'])}\\n\")\n",
    "    f.write(\"-\" * 70 + \"\\n\")\n",
    "    \n",
    "    # Contar tipos de relaciones\n",
    "    rel_types = {}\n",
    "    for rel in neo4j_graph['relationships']:\n",
    "      rel_type = rel['type']\n",
    "      rel_types[rel_type] = rel_types.get(rel_type, 0) + 1\n",
    "    \n",
    "    for rel_type, count in sorted(rel_types.items(), key=lambda x: x[1], reverse=True):\n",
    "      f.write(f\"  {rel_type}: {count}\\n\")\n",
    "    \n",
    "    # Muestra de enfermedades con m√°s informaci√≥n\n",
    "    f.write(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "    f.write(\"MUESTRA DE ENFERMEDADES CON M√ÅS RELACIONES\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    \n",
    "    # Contar relaciones por enfermedad\n",
    "    disease_rels = {}\n",
    "    for rel in neo4j_graph['relationships']:\n",
    "      if rel['from_type'] == 'Disease':\n",
    "        disease = rel['from']\n",
    "        disease_rels[disease] = disease_rels.get(disease, 0) + 1\n",
    "    \n",
    "    # Top 10 enfermedades\n",
    "    top_diseases = sorted(disease_rels.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    for disease_name, rel_count in top_diseases:\n",
    "      # Buscar informaci√≥n de la enfermedad\n",
    "      disease_info = next((d for d in neo4j_graph['nodes']['diseases'] if d['id'] == disease_name), None)\n",
    "      \n",
    "      if disease_info:\n",
    "        f.write(f\"\\n{disease_name}\\n\")\n",
    "        f.write(f\"  Relaciones: {rel_count}\\n\")\n",
    "        if disease_info.get('description'):\n",
    "          desc = disease_info['description'][:200] + \"...\" if len(disease_info['description']) > 200 else disease_info['description']\n",
    "          f.write(f\"  Descripci√≥n: {desc}\\n\")\n",
    "        f.write(f\"  Fuente: {disease_info.get('source', 'N/A')}\\n\")\n",
    "    \n",
    "    # Fuentes de datos\n",
    "    f.write(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "    f.write(\"FUENTES DE DATOS\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\")\n",
    "    sources = set(d.get('source', 'N/A') for d in neo4j_graph['nodes']['diseases'])\n",
    "    for source in sources:\n",
    "      count = sum(1 for d in neo4j_graph['nodes']['diseases'] if d.get('source') == source)\n",
    "      f.write(f\"  {source}: {count} enfermedades\\n\")\n",
    "  \n",
    "  saved_files['summary'] = summary_filename\n",
    "  print(f\"‚úì Guardado resumen en: {summary_filename}\")\n",
    "  \n",
    "  # 4. Crear archivo CSV de nodos (para an√°lisis en pandas)\n",
    "  nodes_csv_filename = f\"medical_kg_nodes_{timestamp}.csv\"\n",
    "  all_nodes = []\n",
    "  for node_type, nodes in neo4j_graph['nodes'].items():\n",
    "    for node in nodes:\n",
    "      all_nodes.append({\n",
    "        'node_type': node_type,\n",
    "        'id': node['id'],\n",
    "        'name': node.get('name', ''),\n",
    "        'description': node.get('description', ''),\n",
    "        'source': node.get('source', '')\n",
    "      })\n",
    "  \n",
    "  nodes_df = pd.DataFrame(all_nodes)\n",
    "  nodes_df.to_csv(nodes_csv_filename, index=False, encoding='utf-8')\n",
    "  saved_files['nodes_csv'] = nodes_csv_filename\n",
    "  print(f\"‚úì Guardados nodos en CSV: {nodes_csv_filename}\")\n",
    "  \n",
    "  # 5. Crear archivo CSV de relaciones\n",
    "  rels_csv_filename = f\"medical_kg_relationships_{timestamp}.csv\"\n",
    "  rels_df = pd.DataFrame(neo4j_graph['relationships'])\n",
    "  rels_df.to_csv(rels_csv_filename, index=False, encoding='utf-8')\n",
    "  saved_files['relationships_csv'] = rels_csv_filename\n",
    "  print(f\"‚úì Guardadas relaciones en CSV: {rels_csv_filename}\")\n",
    "  \n",
    "  print(\"\\n\" + \"=\" * 70)\n",
    "  print(\"ARCHIVOS GUARDADOS EXITOSAMENTE\")\n",
    "  print(\"=\" * 70)\n",
    "  \n",
    "  return saved_files\n",
    "\n",
    "# Guardar resultados\n",
    "saved_files = save_knowledge_graph(neo4j_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422a8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
